{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5dc83a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "reddit = praw.Reddit(client_id = 'UCSwkRYIyqzGgrxlm1Cj5w',\n",
    "                     client_secret = 'Hltij57C_ef1GBTYzHcPzZvX1ZHCHQ',\n",
    "                     username = 'Cold-Cheesecake4900',\n",
    "                     password = 'Cookies42069!',\n",
    "                     user_agent = 'fakebot')\n",
    "#subreddit = reddit.subreddit('datascience')\n",
    "#url = \"https://www.reddit.com/r/funny/comments/3g1jfi/buttons/\"\n",
    "#submission = reddit.submission(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60e27a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do you tell a story with data?\n",
      "Making the jump from Manager to Director? [Update]\n",
      "PSA: Storytelling with data does not mean making up reality as you see fit\n",
      "How to represent multiple lines in same graph effectively.\n"
     ]
    }
   ],
   "source": [
    "#Information from part 1 of the praw tutorial video\n",
    "subreddit = reddit.subreddit('datascience')\n",
    "#Limit might be the key to get everything working\n",
    "hot_python = subreddit.hot(limit = 5)\n",
    "#These are treated as objects. So .something is used to access them\n",
    "for submission in hot_python:\n",
    "    #includes stickied post use this to get rid of them\n",
    "    if not submission.stickied:\n",
    "        print(submission.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d61e7325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "How do you tell a story with data?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41C0C2B0>\n",
      "--------------------\n",
      "Making the jump from Manager to Director? [Update]\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41C1C820>\n",
      "--------------------\n",
      "PSA: Storytelling with data does not mean making up reality as you see fit\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41C1EA00>\n",
      "--------------------\n",
      "How to represent multiple lines in same graph effectively.\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41C22100>\n",
      "--------------------\n",
      "Deployment process of a freelance data scientist?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41C22790>\n",
      "--------------------\n",
      "PHD?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41C22A90>\n",
      "--------------------\n",
      "Data confidence & how to ensure data is reliable\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41C22D90>\n",
      "--------------------\n",
      "What is the relationship between statistics and AI/machine learning?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41C297C0>\n",
      "--------------------\n",
      "Corporate business analyst offer vs. agency course\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41C29C10>\n",
      "--------------------\n",
      "How to automate web scraping?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41C3D7F0>\n",
      "--------------------\n",
      "I have lost all interest in my job and have to come up with defined \"career goals\" to go over with my manager. Please help!\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E417936D0>\n",
      "--------------------\n",
      "Anyone here can't code if someone watches your screen\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E415DEAC0>\n",
      "--------------------\n",
      "Data Science without ML?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E415E3A30>\n",
      "--------------------\n",
      "Using categorical data in predictive analysis.\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E416E9370>\n",
      "--------------------\n",
      "What do you do to keep your knowledge fresh and not get rusty? [D]\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E4172A9D0>\n",
      "--------------------\n",
      "Good resources for learning ML with time series in Python? Some links I've found, but looking for canonical resources.\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41743940>\n",
      "--------------------\n",
      "Looking for project ideas for my Final Year Project\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E4170FFD0>\n",
      "--------------------\n",
      "Data from the Blockchain, how difficult is it to obtain the right data. End project Question\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E4170F6D0>\n",
      "--------------------\n",
      "When do you decide if you've squeezed everything you can out of your data?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E404C3400>\n",
      "--------------------\n",
      "Free websites for exercises and real world applications of programming and coding\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E404C30A0>\n",
      "--------------------\n",
      "What are your best textbooks?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E3FFD68B0>\n",
      "--------------------\n",
      "GPU recommendations for non-cloud ML around $1500\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E416C8E80>\n",
      "--------------------\n",
      "Resume observation from a hiring manager\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41B16A90>\n",
      "--------------------\n",
      "How do you handle job title/job responsibility mismatch with future employers?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41B43DF0>\n",
      "--------------------\n",
      "Offline Database and internal connection\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41B03AC0>\n",
      "--------------------\n",
      "M1 MacBook?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41B03A30>\n",
      "--------------------\n",
      "Why are Data Scientist jobs in demand?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41B03520>\n",
      "--------------------\n",
      "XGBoost use on Forcasting Consumption\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41B28D00>\n",
      "--------------------\n",
      "Why I'm not a manager\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41B37970>\n",
      "--------------------\n",
      "What to say to a potentially helpful colleague I met at a social event at work?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41B37DF0>\n",
      "--------------------\n",
      "Boutique ML Consultancy Head of DS or building a DS capability in a startup?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41B01A60>\n",
      "--------------------\n",
      "Gauging interest in the Data Science field?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41B3B250>\n",
      "--------------------\n",
      "Tough time learning the ropes\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41B3BCD0>\n",
      "--------------------\n",
      "How big is the separation/distinction between Data Science and Statistics?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41B3F430>\n",
      "--------------------\n",
      "As a clinical SAS statistical programmer would it be easier for me to get a DS job or a SWE job?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41B3F940>\n",
      "--------------------\n",
      "Would studying data science have a carryover into pure finance?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41B3FC70>\n",
      "--------------------\n",
      "Remember it always.\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E4174C6D0>\n",
      "--------------------\n",
      "Traversing Graphs solely through embeddings\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41B96E80>\n",
      "--------------------\n",
      "Question to hiring managers, employers: How important is it that…\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41757D30>\n",
      "--------------------\n",
      "Exit Opportunities from Data Science\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E417B5DC0>\n",
      "--------------------\n",
      "Do all of your bullet points in your resume has \"machine learning\" or any other statistical jargon in it?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E417BFBB0>\n",
      "--------------------\n",
      "Which tech/data science jobs cannot be replaced by AI?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41ADA5B0>\n",
      "--------------------\n",
      "Some other stat\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41AECEE0>\n",
      "--------------------\n",
      "Data scientists of reddit: how did you cope with GDPR in your companies?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41AFB910>\n",
      "--------------------\n",
      "How do I prepare for a data science post-doctoral position?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41AD7700>\n",
      "--------------------\n",
      "Welcome to your first data science job\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41AD7B80>\n",
      "--------------------\n",
      "Propensity score matching\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41AC14C0>\n",
      "--------------------\n",
      "Independent DS Consultant - Working with Midmarket Firm - Advice\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41AC15B0>\n",
      "--------------------\n",
      "Who can interpret the following graph?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41AC1B80>\n",
      "--------------------\n",
      "Where to go?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41AF0B80>\n",
      "--------------------\n",
      "SnowFlake vs DataBricks lakehouse or both together\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41AF0A60>\n",
      "--------------------\n",
      "Help with project approach\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41ADD520>\n",
      "--------------------\n",
      "Do I need to learn problem solving to upgrade my skills in data science ? Do you use it in your daily routine ? And what is the best source to learn it ?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41ADDA60>\n",
      "--------------------\n",
      "Help Wanted. Combined Portfolio Weights Sum To Greater Than 100\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41ADDDF0>\n",
      "--------------------\n",
      "What is the most effective way to answer an interview question for a BI/data role where you don't know the answer? Especially where it is done so by design to find out how you handle not knowing something.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41ADC550>\n",
      "--------------------\n",
      "Size of big data to be considered \"big\"?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E418A3640>\n",
      "--------------------\n",
      "How I use Data Science to Trade Options Around Earnings\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E418A3D30>\n",
      "--------------------\n",
      "Is Springboard Legit? Possible juicy drama inside but I hope not.\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E418EFA90>\n",
      "--------------------\n",
      "How would you approach improving a resturant business using data science?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E418E4310>\n",
      "--------------------\n",
      "If you really hate people who analyze data consider publishing your data in a \"pretty\" table with arbitrary random formatting issues and dump the entire db in a plaintext file\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41874E50>\n",
      "--------------------\n",
      "Comprehensive stats overview/refresher for applied scientists?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41879700>\n",
      "--------------------\n",
      "Tools and ressources for a kind of special interview process\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41879E80>\n",
      "--------------------\n",
      "How do you normally clean and prepare data?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41879F10>\n",
      "--------------------\n",
      "I don't know where to start lol. Entry level job demanding 8 years of experience in DE, ETL, BI, DS, DevOp and ML.\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E418537F0>\n",
      "--------------------\n",
      "How to apply for an internal job role without pissing off your manager?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41869EE0>\n",
      "--------------------\n",
      "What's your Data Science Impact?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E4184F6A0>\n",
      "--------------------\n",
      "Research/project ideas?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E4184FDC0>\n",
      "--------------------\n",
      "Researchers found that accelerometer data from smartphones can reveal people's location, passwords, body features, age, gender, level of intoxication, driving style, and be used to reconstruct words spoken next to the device.\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E419925B0>\n",
      "--------------------\n",
      "In an insurance churn task, should precision or recall be prioritized?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41992C70>\n",
      "--------------------\n",
      "Book to teach Business Analytics to a non-technical audience.\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E419B83A0>\n",
      "--------------------\n",
      "Forecasting Airplane Costs in Python\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E419B8040>\n",
      "--------------------\n",
      "Data Source\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E419B88B0>\n",
      "--------------------\n",
      "[Beginner question] What is the right approach to reduce bias?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E419B7610>\n",
      "--------------------\n",
      "data collected by app developers\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E419B3100>\n",
      "--------------------\n",
      "Is advanced statistical modeling considered Data Science work?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E419B3B50>\n",
      "--------------------\n",
      "My job position name not describing my daily agenda\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E4199C430>\n",
      "--------------------\n",
      "Pivoting Data Science\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E4199C820>\n",
      "--------------------\n",
      "What is the demand for data science professionals with expertise in GIS (geographic information systems)?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A78550>\n",
      "--------------------\n",
      "Automated Narrative Content from Data\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A6E8B0>\n",
      "--------------------\n",
      "How to learn to ask the right business questions?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A68AF0>\n",
      "--------------------\n",
      "Data scientist KPI\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A77A90>\n",
      "--------------------\n",
      "Have you needed to learn Python, R, MySQL, GIS tech and other data skills on a fast timeline? What helped you figure out the right path for you?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A73130>\n",
      "--------------------\n",
      "Data Science skills beyond just data and science\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A56BB0>\n",
      "--------------------\n",
      "Version Control on DS Teams\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A36820>\n",
      "--------------------\n",
      "Does Benford's law applicable to DS ?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A4E3A0>\n",
      "--------------------\n",
      "How do you guys deal with imbalanced data in classification models ? How do you assess your model !\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A01190>\n",
      "--------------------\n",
      "How to decide how many nearest neighbors?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A394C0>\n",
      "--------------------\n",
      "Non-Predictable Data Question\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A0E0D0>\n",
      "--------------------\n",
      "If anyone's interested in building apps with a cross-functional team and industry mentorship (FOR Free), this program's open for 5 more days!\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A39E20>\n",
      "--------------------\n",
      "Help me understand what I’m doing wrong\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A9F730>\n",
      "--------------------\n",
      "What to expect as a Data Science Strategist?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A904C0>\n",
      "--------------------\n",
      "Is it possible to scrape all web pages of a website without specifying the exact URL?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A907F0>\n",
      "--------------------\n",
      "B2B Data Enrichment: How does clearbit or leadiq work?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A90D90>\n",
      "--------------------\n",
      "Feeling stuck at my current position and want to get out\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41A93AC0>\n",
      "--------------------\n",
      "Privacy from a Data Science point of view?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41940E20>\n",
      "--------------------\n",
      "Sports Analytics Book\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41947AF0>\n",
      "--------------------\n",
      "People who once chose work life balance/quality of life over job profile or money, do you regret it now?\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41961100>\n",
      "--------------------\n",
      "Can you use linear regression in this case? 3 pointers and years\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E41961A00>\n",
      "--------------------\n",
      "Facebook AI Introduces ‘Neural Databases’, A New Approach Which Enables Machines to Search Unstructured Data and Connect The Fields of Databases and NLP\n",
      "<praw.models.comment_forest.CommentForest object at 0x0000022E419539D0>\n"
     ]
    }
   ],
   "source": [
    "#Information from part 2 of the praw tutorial video\n",
    "#can add .list() to the end of this. Lists all the top level comments, then lower-level, then level beneath that\n",
    "#Can use replace_more(limit = n) to load in more comments\n",
    "#comments = submission.comments.list()\n",
    "#This is show replies from the third submission\n",
    "#for comment in comments:\n",
    "#comments = submission.comments.replace_more(limit = 2)\n",
    "#for comment in submission.comments.list():\n",
    "    #print(20*'-')\n",
    "    #Can use dir(comment.body) to obtain attributes\n",
    "    #print(comment.body)\n",
    "    #print('Parent ID:', comment.parent())\n",
    "    #print('Comment ID:', comment.id)\n",
    "    \n",
    "top_data_sci = subreddit.hot()\n",
    "for submission in top_data_sci:\n",
    "    #includes stickied post use this to get rid of them\n",
    "    if not submission.stickied:\n",
    "        print(20*'-')\n",
    "        print(submission.title)\n",
    "        print(submission.comments)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dfc2e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#news_subreddit = reddit.subreddit('news')\n",
    "#Limit might be the key to get everything working\n",
    "#hot_news = news_subreddit.hot(limit = 100)\n",
    "#These are treated as objects. So .something is used to access them\n",
    "#for submission in hot_news:\n",
    "    #includes stickied post use this to get rid of them\n",
    "    #if not submission.stickied:\n",
    "        #print(20*'-')\n",
    "        #print(submission.title)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "014e4db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temporary dump for useful things i've used for the project but had to remove\n",
    "#datetime.utcfromtimestamp(submission.created_utc) >= datetime(2021,1,1):\n",
    "\n",
    "#Import datetime so that posts can be sorted within the year\n",
    "#from datetime import datetime, timedelta\n",
    "\n",
    "#print(str(datetime.utcfromtimestamp(submission.created_utc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac3ffbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nuclear Option: USE THIS TO OBTAIN EVERYTHING BUT THE COMMENTS\n",
    "\n",
    "import praw\n",
    "reddit = praw.Reddit(client_id = 'UCSwkRYIyqzGgrxlm1Cj5w',\n",
    "                     client_secret = 'Hltij57C_ef1GBTYzHcPzZvX1ZHCHQ',\n",
    "                     username = 'Cold-Cheesecake4900',\n",
    "                     password = 'Cookies42069!',\n",
    "                     user_agent = 'fakebot')\n",
    "\n",
    "# your code for step 2 goes here\n",
    "from datetime import datetime\n",
    "\n",
    "#Access data science subreddit and limit to top 100 posts\n",
    "top_data_sci = reddit.subreddit('news').top(limit = 600)\n",
    "\n",
    "title_list = []\n",
    "\n",
    "up_list = []\n",
    "\n",
    "time_list = []\n",
    "\n",
    "comments_list = []\n",
    "\n",
    "#Submission in the for loop searchs the posts in the subreddit \n",
    "for submission in top_data_sci:\n",
    "    \n",
    "    #Store the unix time for posts\n",
    "    submission_time = submission.created_utc\n",
    "    \n",
    "    submission.comments.replace_more(limit=0)\n",
    "    #comments = submission.comments.list()\n",
    "\n",
    "    #For loop unpacks tubles. Limits the number of comments that appear from a single post to 3\n",
    "    #for comment, top_level_comments in (zip(range(3), submission.comments)):\n",
    "    for top_level_comments in submission.comments[:1]:\n",
    "        \n",
    "        if submission.ups > 50 and len(submission.title.split()) > 5 and \\\n",
    "        submission_time >= 1609477200:\n",
    "        \n",
    "            #print(20*'-')\n",
    "            \n",
    "            #print(\"The title of the post: \", submission.title)\n",
    "            \n",
    "            #temp_title_list.append(submission.title)\n",
    "            #for title in temp_title_list:\n",
    "                #if title not in submission_title_list:\n",
    "                    #submission_title_list.append(title)\n",
    "            \n",
    "            title_list.append(submission.title)\n",
    "            up_list.append(submission.ups)\n",
    "            submission_times = list(str(datetime.fromtimestamp(submission_time))[:10])\n",
    "            time_list.append(str(datetime.fromtimestamp(submission_time))[:10])\n",
    "            #Need help logic here is wrong. Somehow coupled showing three comments to everything\n",
    "            #Using this loop will get me a list of upvotes but if different submissions have the \n",
    "            #same number of upvotes they will be removed\n",
    "            #print(\"Number of upvotes: \", submission.ups)\n",
    "            \n",
    "            #temp_ups_list.append(submission.ups)\n",
    "            #for up in temp_ups_list:\n",
    "                #if up not in submission_post_score_list:\n",
    "                    #submission_post_score_list.append(up)\n",
    "            \n",
    "            #print(\"Length of title: \", len(submission.title.split()))\n",
    "            \n",
    "            #temp_title_list.append(submission.title)\n",
    "            #for title in temp_title_list:\n",
    "                #if title not in submission_title_list:\n",
    "                    #submission_title_list.append(title)                            \n",
    "            \n",
    "            #print(\"This post was submitted on: \" + str(datetime.fromtimestamp(submission_time))[:10])\n",
    "            #submission_times = list(str(datetime.fromtimestamp(submission_time))[:10])\n",
    "            #temp_time_list.append(str(datetime.fromtimestamp(submission_time))[:10])\n",
    "            #for time in temp_time_list:\n",
    "                    #if time not in submission_time_list:\n",
    "                        #submission_time_list.append(str(datetime.fromtimestamp(submission_time))[:10])\n",
    "                                                \n",
    "            #print(20*'-', \"Comments Start Here \\n\")\n",
    "            #print(top_level_comments.body)\n",
    "            #comments_list.append(top_level_comment.body)\n",
    "            #submission_comments = list(submission.comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f99dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this to get comments\n",
    "import pandas as pd\n",
    "\n",
    "data_science_subreddit = reddit.subreddit('news').top(limit = 600)\n",
    "comment_list = []\n",
    "for submission in data_science_subreddit:\n",
    "    \n",
    "    submission_time = submission.created_utc\n",
    "    \n",
    "    for top_level_comments in submission.comments.list()[:3]:\n",
    "        \n",
    "        if submission.ups > 50 and len(submission.title.split()) > 5 and \\\n",
    "        submission_time >= 1609477200:\n",
    "           \n",
    "            submission.comments.replace_more(limit=0)    \n",
    "            #print(20*'-')\n",
    "            #print(\"The title of the post: \", submission.title)\n",
    "            #print(top_level_comments.body)\n",
    "            comment_list.append(top_level_comments.body)\n",
    "top_comment1 = []\n",
    "top_comment2 = []\n",
    "top_comment3 = []\n",
    "for index in range(0, len(comment_list), 3):\n",
    "    top_comment1.append(comment_list[index])\n",
    "for index in range(1, len(comment_list), 3):\n",
    "    top_comment2.append(comment_list[index])\n",
    "for index in range(2, len(comment_list), 3):\n",
    "    top_comment3.append(comment_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38a361f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max value is  249366\n",
      "The min value is  80986\n",
      "The range is  168380\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Set up data set with column names and populate with appropriate lists\n",
    "my_data_set = {'Date' : time_list, 'Post score' : up_list, 'Post title' : title_list,\n",
    "              'Top comment 1' : top_comment1, 'Top comment 2' : top_comment2, 'Top comment 3' : top_comment3}\n",
    "#Save data frame\n",
    "myDF = pd.DataFrame(my_data_set)\n",
    "#Drop rows down to 101\n",
    "myDF = myDF.drop(myDF.index[101:147], axis = 0)\n",
    "#myDF.tail()\n",
    "column = myDF['Post score']\n",
    "#myDF.mean(axis = 'index')\n",
    "print(\"The max value is \", column.max())\n",
    "print(\"The min value is \", column.min())\n",
    "print(\"The range is \", column.max() - column.min())\n",
    "#myDF.to_csv(\"Reddit Videos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0701775c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
