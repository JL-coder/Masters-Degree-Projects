{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa90d0f1",
   "metadata": {},
   "source": [
    "\n",
    "For this case study, you will perform a classification task on a WiFi dataset, and also explore the question, \"Is more data useful for a classification task?\"\n",
    "\n",
    "The dataset you will use can be found on: https://archive.ics.uci.edu/ml/datasets/ujiindoorloc .\n",
    "\n",
    "**\\[Step 1\\]** Once you examine the data sets, you will find that there is a training set and a validation set. You can use them to build your classification model. You might need to determine what are your features and targets. You can also do some engineering on features and targets if necessary.\n",
    "\n",
    "**\\[Step 2\\]** But, which algorithm should you use with your model? You can refer to the scikit-learn cheat sheet: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html, and try three algorithms. Some suggestions are: LinearSVC, Logistic Regression, KNN classifier, SVC, Random Forest (as an example of Ensemble Learning) etc. Perform one experiment using each and observe the performance of each model. Note which is the best performing model.\n",
    "\n",
    "**\\[Step 3\\]** Once the previous step is done, observe if more data is useful for a classification task using the best performing model from the previous step. For this, randomly select 20% of the training samples, but keep the size of the validation set the same. Note the performance. Then also try with 40%, 60%, 80% and 100% of the training samples. Perform three experiments for each selection. This means, for 20% you will do three experiments, 40% three experiments etc. Find the average of three experiments for each selection and plot them using a chart of your choice.\n",
    "\n",
    "**\\[Step 4\\]** Publish your finding in presentation slides. Like case study 1, three of you will be randomly chosen to present your work in front of the class. The slides should inform the audience about:\n",
    "\n",
    "* the objective of the case study\n",
    "* the data (features and targets)\n",
    "* things you have done (e.g. why you selected a specific classification model)\n",
    "* your findings.\n",
    "\n",
    "\n",
    "**Things to note**:\n",
    "\n",
    "* **Type of task**: classification\n",
    "* **Features**: you choose.\n",
    "* **Feature engineering**: You are welcome to do so.\n",
    "* **Target**: Use a combination of features to learn from and identify the location. Ignore the SPACEID column.\n",
    "\n",
    "* In some cases, Normalization may result in reduced accuracy.\n",
    "* You must write enough comments so that anybody with some programming knowledge can understand your code.\n",
    "\n",
    "**Grading Criteria**:\n",
    "\n",
    "* [15 + 15] Data set preparation: Choosing your $X$ and $y$. Feature Engineering.\n",
    "* [15 + 15 + 15] Three experiments using three algorithms.  \n",
    "* [15] Observing the effects of more data using five sets of random samples of different sizes from the training set. \n",
    "* [10] Presentation slides\n",
    "\n",
    "**What to submit**:\n",
    "\n",
    "Put the Jupyter Notebook file and the .csv file in a folder. Then convert your presentation slides in to a PDF file and put it in the same folder. Zip the folder. After zipping, it should have the extension .zip. The name of the .zip file should be firstname_lastname_casestudy_1.zip . Upload the .zip file on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f46ef5",
   "metadata": {},
   "source": [
    "# Step 1: Data Exploration and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42b2b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all necessary libraries for the study\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, linear_model, feature_selection, metrics\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ddef234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAP001</th>\n",
       "      <th>WAP002</th>\n",
       "      <th>WAP003</th>\n",
       "      <th>WAP004</th>\n",
       "      <th>WAP005</th>\n",
       "      <th>WAP006</th>\n",
       "      <th>WAP007</th>\n",
       "      <th>WAP008</th>\n",
       "      <th>WAP009</th>\n",
       "      <th>WAP010</th>\n",
       "      <th>...</th>\n",
       "      <th>WAP520</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>FLOOR</th>\n",
       "      <th>BUILDINGID</th>\n",
       "      <th>SPACEID</th>\n",
       "      <th>RELATIVEPOSITION</th>\n",
       "      <th>USERID</th>\n",
       "      <th>PHONEID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7541.264300</td>\n",
       "      <td>4.864921e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7536.621200</td>\n",
       "      <td>4.864934e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-97</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7519.152400</td>\n",
       "      <td>4.864950e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371714095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7524.570400</td>\n",
       "      <td>4.864934e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7632.143600</td>\n",
       "      <td>4.864982e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>1369909710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7533.896200</td>\n",
       "      <td>4.864939e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7519.152400</td>\n",
       "      <td>4.864950e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7527.451100</td>\n",
       "      <td>4.864929e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7559.497300</td>\n",
       "      <td>4.864888e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371714307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7510.437173</td>\n",
       "      <td>4.864949e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371714128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
       "0     100     100     100     100     100     100     100     100     100   \n",
       "1     100     100     100     100     100     100     100     100     100   \n",
       "2     100     100     100     100     100     100     100     -97     100   \n",
       "3     100     100     100     100     100     100     100     100     100   \n",
       "4     100     100     100     100     100     100     100     100     100   \n",
       "5     100     100     100     100     100     100     100     100     100   \n",
       "6     100     100     100     100     100     100     100     100     100   \n",
       "7     100     100     100     100     100     100     100     100     100   \n",
       "8     100     100     100     100     100     100     100     100     100   \n",
       "9     100     100     100     100     100     100     100     100     100   \n",
       "\n",
       "   WAP010  ...  WAP520    LONGITUDE      LATITUDE  FLOOR  BUILDINGID  SPACEID  \\\n",
       "0     100  ...     100 -7541.264300  4.864921e+06      2           1      106   \n",
       "1     100  ...     100 -7536.621200  4.864934e+06      2           1      106   \n",
       "2     100  ...     100 -7519.152400  4.864950e+06      2           1      103   \n",
       "3     100  ...     100 -7524.570400  4.864934e+06      2           1      102   \n",
       "4     100  ...     100 -7632.143600  4.864982e+06      0           0      122   \n",
       "5     100  ...     100 -7533.896200  4.864939e+06      2           1      105   \n",
       "6     100  ...     100 -7519.152400  4.864950e+06      2           1      103   \n",
       "7     100  ...     100 -7527.451100  4.864929e+06      2           1      101   \n",
       "8     100  ...     100 -7559.497300  4.864888e+06      2           1      112   \n",
       "9     100  ...     100 -7510.437173  4.864949e+06      2           1      103   \n",
       "\n",
       "   RELATIVEPOSITION  USERID  PHONEID   TIMESTAMP  \n",
       "0                 2       2       23  1371713733  \n",
       "1                 2       2       23  1371713691  \n",
       "2                 2       2       23  1371714095  \n",
       "3                 2       2       23  1371713807  \n",
       "4                 2      11       13  1369909710  \n",
       "5                 2       2       23  1371713841  \n",
       "6                 2       2       23  1371713883  \n",
       "7                 2       2       23  1371713775  \n",
       "8                 2       2       23  1371714307  \n",
       "9                 1       2       23  1371714128  \n",
       "\n",
       "[10 rows x 529 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read dataframe into jupyter and display the first 10 rows\n",
    "df = pd.read_csv(\"trainingData.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4eb8609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values (There are none)\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6056e27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19937 entries, 0 to 19936\n",
      "Columns: 529 entries, WAP001 to TIMESTAMP\n",
      "dtypes: float64(2), int64(527)\n",
      "memory usage: 80.5 MB\n"
     ]
    }
   ],
   "source": [
    "#Check the information associated with the data frame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5627b717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       11\n",
       "1       24\n",
       "2       24\n",
       "3       24\n",
       "4        2\n",
       "        ..\n",
       "1106    23\n",
       "1107    23\n",
       "1108     0\n",
       "1109     0\n",
       "1110     0\n",
       "Name: Building_Code, Length: 1111, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The most useful way to classify location is by using the buildingID and floor. However we can only have one y value so they have \n",
    "#to be combined. I turned the columns into strings so that the numbers can be concatenated into a single number called building\n",
    "#code. The first number represents the buildingID while the second represents the floor. \n",
    "df['BUILDINGID'] = df['BUILDINGID'].apply(str)\n",
    "df['FLOOR'] = df['FLOOR'].apply(str)\n",
    "df['Building_Code'] = df['BUILDINGID'] + df['FLOOR']\n",
    "df['Building_Code'] = df['Building_Code'].apply(int)\n",
    "df['Building_Code']\n",
    "\n",
    "#Load up the validation dataset\n",
    "val_df = pd.read_csv(\"validationData.csv\")\n",
    "\n",
    "# Do the same thing for the validation dataset and add the building code\n",
    "val_df['BUILDINGID'] = val_df['BUILDINGID'].apply(str)\n",
    "val_df['FLOOR'] = val_df['FLOOR'].apply(str)\n",
    "val_df['Building_Code'] = val_df['BUILDINGID'] + val_df['FLOOR']\n",
    "val_df['Building_Code'] = val_df['Building_Code'].apply(int)\n",
    "val_df['Building_Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50c69bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23    2709\n",
       "21    2162\n",
       "20    1942\n",
       "22    1577\n",
       "11    1484\n",
       "2     1443\n",
       "12    1396\n",
       "3     1391\n",
       "10    1368\n",
       "1     1356\n",
       "24    1102\n",
       "0     1059\n",
       "13     948\n",
       "Name: Building_Code, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I did this to check to make sure that by concatenating the two columns the new building code does not have 3 values\n",
    "# which would throw off the prediction accuracy (and be hard for us humans to interpret as we would have no way of knowing\n",
    "# which part is the buildingID and which is the floorID). Three building codes have only one value, I assume that the \n",
    "# buildingID was zero and python removed the zero. I decided to go ahead with this method as the context of the location is \n",
    "# not lost by the removed zero and I dont expect the prediction algorithms to misclassify. \n",
    "# I should still be able to predict and interpret the correct location with this building code knowing that 2 just means\n",
    "# buildingID = 0 and FloorID = 2.\n",
    "df['Building_Code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb635840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are distinct phone ID groups. There are 16 distinct phoneID groups\n",
    "df.groupby(['PHONEID']).ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb0e00be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And 18 distinct userID groups\n",
    "df.groupby(['USERID']).ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71753238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You would think that there is a connection between phoneID and userID but there are different numbers of groups in the\n",
    "# columns. Might bet worth trying different combinations of these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2a99c4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2013-06-20 07:35:33\n",
       "1       2013-06-20 07:34:51\n",
       "2       2013-06-20 07:41:35\n",
       "3       2013-06-20 07:36:47\n",
       "4       2013-05-30 10:28:30\n",
       "                ...        \n",
       "19932   2013-06-20 06:44:43\n",
       "19933   2013-06-20 06:40:02\n",
       "19934   2013-06-20 06:48:41\n",
       "19935   2013-06-20 06:50:49\n",
       "19936   2013-06-20 06:50:25\n",
       "Name: Converted_Time, Length: 19937, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Time may be independent of location but if the people connecting to the different access points are moving in certain \n",
    "#patterns it might be a useful metric to include. Coverted to year-month-day format so that humans can read it.\n",
    "#Data taken over about a 45 min interval. \n",
    "df['TIMESTAMP'].sort_values()\n",
    "df['Converted_Time'] = pd.to_datetime(df['TIMESTAMP'], unit = 's')\n",
    "df['Converted_Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b7094d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For x values to be tested longitude, latitude, and spaceID were removed from early consideration because they are similar\n",
    "# to the y value in terms of our goal and didn't add to the accuracy.\n",
    "# I attempted to use TIMESTAMP as part of my model but the accuracy fell with its inclusion so it was removed from\n",
    "# consideration. The large values of unix time likely threw off it off.\n",
    "#Finally, the columns for relative position, userID, and phoneId while I hoped would add to the accuracy in fact caused it\n",
    "#to fall when tested. This resulted in the columns for WAP001 to WAP520 to be chosen as the predictor columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efded4af",
   "metadata": {},
   "source": [
    "# Step 2 - Apply Algorithms to the training set and see how they perform on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89527477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign connection data for test dataframe and validation dataframe to a variable\n",
    "connectionData = df.iloc[:,0:520]\n",
    "valConnectionData = val_df.iloc[:,0:520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90d4f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use all the samples from the training and validation data (no splitting of datasets)\n",
    "\n",
    "#Create preprocessing object for max abs scaler\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "\n",
    "# Fit and transform the predictor columns for training and validation datasets\n",
    "xtrain_maxabs = max_abs_scaler.fit_transform(connectionData)\n",
    "xval_maxabs = max_abs_scaler.fit_transform(valConnectionData)\n",
    "\n",
    "#Select out response columns from data frames\n",
    "y = df.loc[:,['Building_Code']]\n",
    "\n",
    "val_y = val_df['Building_Code']\n",
    "\n",
    "#Note from unscaled (not normailized) vs scaled (normalized) tests:\n",
    "#Unscaled dataframes performed overall better than the scaled dataframes with an F-1 score usually a few hundredths of a point higher\n",
    "#higher. However, the unscaled dataframes for most of my classifiers still mostly missed the 0.8 F-1 mark that I am looking \n",
    "#for. Random Forest performed the best and was similar (had the same F-1 score) in scaled and unscaled tests. \n",
    "#I continued using scaled data throughout the subsequent experiments (and in the shown experiments) since there was no real\n",
    "#difference in accuracy for the classifier I chose to use in step 3 (since I cant use the others due to low accuracy)\n",
    "#and it came down to personal preference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6055076f",
   "metadata": {},
   "source": [
    "## 1. Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79eb5cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import important libraries\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d72234f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the classifier. Use default parameters for the class\n",
    "lsvc = LinearSVC(verbose = 0)\n",
    "\n",
    "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
    "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5919f08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9277223253247731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "#Fit the model on the training data and check the accuracy score\n",
    "lsvc.fit(xtrain_maxabs, y)\n",
    "score = lsvc.score(connectionData, y)\n",
    "print(\"Score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "687648e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.75        78\n",
      "           1       0.77      0.83      0.80       208\n",
      "           2       0.78      0.54      0.64       165\n",
      "           3       0.65      0.87      0.74        85\n",
      "          10       0.53      0.70      0.60        30\n",
      "          11       0.92      0.58      0.71       143\n",
      "          12       0.62      0.69      0.65        87\n",
      "          13       0.62      0.85      0.71        47\n",
      "          20       0.48      0.88      0.62        24\n",
      "          21       0.88      0.82      0.85       111\n",
      "          22       0.71      0.37      0.49        54\n",
      "          23       0.37      0.95      0.53        40\n",
      "          24       0.95      0.46      0.62        39\n",
      "\n",
      "    accuracy                           0.70      1111\n",
      "   macro avg       0.70      0.71      0.67      1111\n",
      "weighted avg       0.75      0.70      0.71      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now to see how well it predicts y from the validation set. \n",
    "#Create a y prediction variable and load up a classification report.\n",
    "yprediction = lsvc.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, yprediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On the unscaled data:\n",
    "# Accuracy Score (Training Data): 0.8497767969102673\n",
    "# # F-1 Score Acccuracy: 0.66"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277abc5",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1ba9349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9655916135827858\n"
     ]
    }
   ],
   "source": [
    "#Import the libraries \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#instantiate the model\n",
    "logregression = LogisticRegression(max_iter=10000)\n",
    "\n",
    "#Fit the model\n",
    "logregression.fit(xtrain_maxabs, y)\n",
    "\n",
    "log_score = logregression.score(xtrain_maxabs, y)\n",
    "print(\"Score: \", log_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c526c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.82        78\n",
      "           1       0.89      0.82      0.85       208\n",
      "           2       0.73      0.81      0.77       165\n",
      "           3       0.76      0.80      0.78        85\n",
      "          10       0.48      0.73      0.58        30\n",
      "          11       0.95      0.60      0.74       143\n",
      "          12       0.62      0.78      0.69        87\n",
      "          13       0.64      0.81      0.72        47\n",
      "          20       0.79      0.92      0.85        24\n",
      "          21       0.88      0.93      0.90       111\n",
      "          22       0.92      0.61      0.73        54\n",
      "          23       0.58      0.97      0.73        40\n",
      "          24       0.96      0.56      0.71        39\n",
      "\n",
      "    accuracy                           0.78      1111\n",
      "   macro avg       0.77      0.78      0.76      1111\n",
      "weighted avg       0.81      0.78      0.78      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now to see how well it predicts y from the validation set. \n",
    "#Create a y prediction variable and load up a classification report.\n",
    "logYPrediction = logregression.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, logYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On the unscaled data logistic regression takes a super long time to run so the important bits that are found are recorded\n",
    "# here so I don't have to keep running every single time I want to check:\n",
    "# Accuracy Score (Training Data): 0.9715102573105282\n",
    "# # F-1 Score Acccuracy: 0.73"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35a183f",
   "metadata": {},
   "source": [
    "## 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cdc21ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-770a27b98331>:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xtrain_maxabs, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9972413101268998\n"
     ]
    }
   ],
   "source": [
    "#Import the libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "#Create a classifier\n",
    "clf=RandomForestClassifier(n_estimators=6)\n",
    "\n",
    "#Train the model and set up the y prediction variable\n",
    "clf.fit(xtrain_maxabs, y)\n",
    "\n",
    "rf_score = clf.score(xtrain_maxabs, y)\n",
    "print(\"Score: \", rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e37eb44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.94      0.80        78\n",
      "           1       0.94      0.85      0.89       208\n",
      "           2       0.91      0.87      0.89       165\n",
      "           3       0.87      0.87      0.87        85\n",
      "          10       0.57      0.80      0.67        30\n",
      "          11       0.97      0.58      0.72       143\n",
      "          12       0.63      0.86      0.73        87\n",
      "          13       0.73      0.91      0.81        47\n",
      "          20       0.81      0.88      0.84        24\n",
      "          21       0.83      0.90      0.86       111\n",
      "          22       0.75      0.44      0.56        54\n",
      "          23       0.54      0.90      0.67        40\n",
      "          24       0.82      0.46      0.59        39\n",
      "\n",
      "    accuracy                           0.80      1111\n",
      "   macro avg       0.77      0.79      0.76      1111\n",
      "weighted avg       0.83      0.80      0.80      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now test the validation set on the fitted model\n",
    "rfYPrediction = clf.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, rfYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea51f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On the unscaled/scaled data Random Forest appears to do the best with logistic regression performing second, and linear svc\n",
    "# bringing up the rear. Logistic regression performed better on the scaled data as did linear svc but neither reached an\n",
    "# accuracy of 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd84ae4",
   "metadata": {},
   "source": [
    "# Random Forest performed the best in terms of accuracy and F-1 score on the validation set. I will be using it moving foreword."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ded0712",
   "metadata": {},
   "source": [
    "# Step 3 Perform three experiments on Random Forest and see how it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efafe6e",
   "metadata": {},
   "source": [
    "### 20% Training Set Data, Validation Set Same Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1213412a",
   "metadata": {},
   "source": [
    "#### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a249653d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9947328818660647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-8cac0707cd1c>:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xtrain_maxabs, ytrain)\n"
     ]
    }
   ],
   "source": [
    "#Split the training data into testing and training parts. Use 80% of it as test data, remaining is training.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(connectionData, y, test_size = 0.80)\n",
    "\n",
    "#Transform the training set with the appropriate scaler.\n",
    "xtrain_maxabs = max_abs_scaler.fit_transform(xtrain)\n",
    "\n",
    "#Create a classifier\n",
    "clf=RandomForestClassifier(n_estimators=6)\n",
    "\n",
    "#Train the model and set up the y prediction variable\n",
    "clf.fit(xtrain_maxabs, ytrain)\n",
    "\n",
    "rf_score = clf.score(xtrain_maxabs, ytrain)\n",
    "print(\"Score: \", rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25493159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.94      0.69        78\n",
      "           1       0.90      0.71      0.79       208\n",
      "           2       0.80      0.72      0.76       165\n",
      "           3       0.74      0.79      0.77        85\n",
      "          10       0.69      0.73      0.71        30\n",
      "          11       0.95      0.57      0.71       143\n",
      "          12       0.58      0.83      0.68        87\n",
      "          13       0.67      0.83      0.74        47\n",
      "          20       0.50      0.88      0.64        24\n",
      "          21       0.89      0.79      0.84       111\n",
      "          22       0.69      0.44      0.54        54\n",
      "          23       0.47      0.90      0.62        40\n",
      "          24       0.76      0.49      0.59        39\n",
      "\n",
      "    accuracy                           0.73      1111\n",
      "   macro avg       0.71      0.74      0.70      1111\n",
      "weighted avg       0.77      0.73      0.73      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now test the validation set on the fitted model\n",
    "rfYPrediction = clf.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, rfYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62fdd86",
   "metadata": {},
   "source": [
    "#### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5013eab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9957361424630048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-d3c96b9b9b7b>:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xtrain_maxabs, ytrain)\n"
     ]
    }
   ],
   "source": [
    "#Split the training data into testing and training parts. Use 80% of it as test data, remaining is training.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(connectionData, y, test_size = 0.80)\n",
    "#Transform the training set with the appropriate scaler.\n",
    "xtrain_maxabs = max_abs_scaler.fit_transform(xtrain)\n",
    "#Train the model and set up the y prediction variable\n",
    "clf.fit(xtrain_maxabs, ytrain)\n",
    "\n",
    "rf_score = clf.score(xtrain_maxabs, ytrain)\n",
    "print(\"Score: \", rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbcc5acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.88      0.75        78\n",
      "           1       0.82      0.73      0.77       208\n",
      "           2       0.77      0.72      0.75       165\n",
      "           3       0.78      0.81      0.79        85\n",
      "          10       0.56      0.73      0.64        30\n",
      "          11       0.92      0.57      0.70       143\n",
      "          12       0.54      0.77      0.63        87\n",
      "          13       0.64      0.77      0.70        47\n",
      "          20       0.61      0.83      0.70        24\n",
      "          21       0.77      0.82      0.79       111\n",
      "          22       0.67      0.33      0.44        54\n",
      "          23       0.43      0.78      0.55        40\n",
      "          24       0.89      0.41      0.56        39\n",
      "\n",
      "    accuracy                           0.71      1111\n",
      "   macro avg       0.70      0.70      0.68      1111\n",
      "weighted avg       0.75      0.71      0.71      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now test the validation set on the fitted model\n",
    "rfYPrediction = clf.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, rfYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c993ee1",
   "metadata": {},
   "source": [
    "#### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6889947c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9934788061198896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-d3c96b9b9b7b>:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xtrain_maxabs, ytrain)\n"
     ]
    }
   ],
   "source": [
    "#Split the training data into testing and training parts. Use 80% of it as test data, remaining is training.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(connectionData, y, test_size = 0.80)\n",
    "#Transform the training set with the appropriate scaler.\n",
    "xtrain_maxabs = max_abs_scaler.fit_transform(xtrain)\n",
    "#Train the model and set up the y prediction variable\n",
    "clf.fit(xtrain_maxabs, ytrain)\n",
    "\n",
    "rf_score = clf.score(xtrain_maxabs, ytrain)\n",
    "print(\"Score: \", rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b1042e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.84        78\n",
      "           1       0.84      0.85      0.84       208\n",
      "           2       0.87      0.71      0.78       165\n",
      "           3       0.81      0.86      0.83        85\n",
      "          10       0.52      0.73      0.61        30\n",
      "          11       0.86      0.51      0.64       143\n",
      "          12       0.58      0.87      0.69        87\n",
      "          13       0.74      0.83      0.78        47\n",
      "          20       0.67      0.83      0.74        24\n",
      "          21       0.86      0.86      0.86       111\n",
      "          22       0.68      0.52      0.59        54\n",
      "          23       0.42      0.82      0.56        40\n",
      "          24       0.92      0.28      0.43        39\n",
      "\n",
      "    accuracy                           0.75      1111\n",
      "   macro avg       0.73      0.74      0.71      1111\n",
      "weighted avg       0.79      0.75      0.75      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now test the validation set on the fitted model\n",
    "rfYPrediction = clf.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, rfYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cbcd4b",
   "metadata": {},
   "source": [
    "#### Average of Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a80804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy for 20% Training Data:  0.9951509071147897\n",
      "Average F-1 Accuracy for 20% Training Data:  0.7433333333333333\n"
     ]
    }
   ],
   "source": [
    "average_accuracy20 = (0.9942312515675947 + 0.9964885879107098 + 0.9947328818660647)/3\n",
    "average_F120 = (0.75 + 0.74 + 0.74)/3\n",
    "print(\"Average Accuracy for 20% Training Data: \", average_accuracy20)\n",
    "print(\"Average F-1 Accuracy for 20% Training Data: \", average_F120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c892889",
   "metadata": {},
   "source": [
    "### 40% Training Set Data, Validation Set Same Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b536e",
   "metadata": {},
   "source": [
    "#### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30c03957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9954853273137697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-1b9aa03e7239>:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xtrain_maxabs, ytrain)\n"
     ]
    }
   ],
   "source": [
    "#Split the training data into testing and training parts. Use 60% of it as test data, remaining is training.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(connectionData, y, test_size = 0.60)\n",
    "\n",
    "#Transform the training set with the appropriate scaler.\n",
    "xtrain_maxabs = max_abs_scaler.fit_transform(xtrain)\n",
    "\n",
    "#Create a classifier\n",
    "clf=RandomForestClassifier(n_estimators=6)\n",
    "\n",
    "#Train the model and set up the y prediction variable\n",
    "clf.fit(xtrain_maxabs, ytrain)\n",
    "\n",
    "rf_score = clf.score(xtrain_maxabs, ytrain)\n",
    "print(\"Score: \", rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f35542f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.90      0.70        78\n",
      "           1       0.91      0.74      0.82       208\n",
      "           2       0.84      0.82      0.83       165\n",
      "           3       0.85      0.84      0.84        85\n",
      "          10       0.59      0.80      0.68        30\n",
      "          11       0.93      0.54      0.68       143\n",
      "          12       0.58      0.87      0.70        87\n",
      "          13       0.71      0.79      0.75        47\n",
      "          20       0.57      0.83      0.68        24\n",
      "          21       0.80      0.78      0.79       111\n",
      "          22       0.64      0.50      0.56        54\n",
      "          23       0.58      0.90      0.71        40\n",
      "          24       1.00      0.56      0.72        39\n",
      "\n",
      "    accuracy                           0.75      1111\n",
      "   macro avg       0.74      0.76      0.73      1111\n",
      "weighted avg       0.79      0.75      0.75      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now test the validation set on the fitted model\n",
    "rfYPrediction = clf.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, rfYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a6ef42",
   "metadata": {},
   "source": [
    "#### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d478fecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9969902182091799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-0a366591fbea>:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xtrain_maxabs, ytrain)\n"
     ]
    }
   ],
   "source": [
    "#Split the training data into testing and training parts. Use 60% of it as test data, remaining is training.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(connectionData, y, test_size = 0.60)\n",
    "#Transform the training set with the appropriate scaler.\n",
    "xtrain_maxabs = max_abs_scaler.fit_transform(xtrain)\n",
    "#Train the model and set up the y prediction variable\n",
    "clf.fit(xtrain_maxabs, ytrain)\n",
    "\n",
    "rf_score = clf.score(xtrain_maxabs, ytrain)\n",
    "print(\"Score: \", rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2886b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81        78\n",
      "           1       0.90      0.82      0.86       208\n",
      "           2       0.87      0.78      0.82       165\n",
      "           3       0.83      0.86      0.84        85\n",
      "          10       0.61      0.77      0.68        30\n",
      "          11       0.92      0.57      0.70       143\n",
      "          12       0.62      0.85      0.72        87\n",
      "          13       0.60      0.81      0.69        47\n",
      "          20       0.64      0.75      0.69        24\n",
      "          21       0.84      0.87      0.86       111\n",
      "          22       0.78      0.54      0.64        54\n",
      "          23       0.57      0.95      0.71        40\n",
      "          24       1.00      0.54      0.70        39\n",
      "\n",
      "    accuracy                           0.78      1111\n",
      "   macro avg       0.76      0.77      0.75      1111\n",
      "weighted avg       0.81      0.78      0.78      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now test the validation set on the fitted model\n",
    "rfYPrediction = clf.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, rfYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6609ee21",
   "metadata": {},
   "source": [
    "#### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bed4e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9969902182091799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-0a366591fbea>:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xtrain_maxabs, ytrain)\n"
     ]
    }
   ],
   "source": [
    "#Split the training data into testing and training parts. Use 60% of it as test data, remaining is training.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(connectionData, y, test_size = 0.60)\n",
    "#Transform the training set with the appropriate scaler.\n",
    "xtrain_maxabs = max_abs_scaler.fit_transform(xtrain)\n",
    "#Train the model and set up the y prediction variable\n",
    "clf.fit(xtrain_maxabs, ytrain)\n",
    "\n",
    "rf_score = clf.score(xtrain_maxabs, ytrain)\n",
    "print(\"Score: \", rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18c67380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.80        78\n",
      "           1       0.91      0.82      0.86       208\n",
      "           2       0.83      0.85      0.84       165\n",
      "           3       0.86      0.82      0.84        85\n",
      "          10       0.54      0.83      0.66        30\n",
      "          11       0.93      0.58      0.72       143\n",
      "          12       0.65      0.86      0.74        87\n",
      "          13       0.62      0.77      0.69        47\n",
      "          20       0.71      0.83      0.77        24\n",
      "          21       0.84      0.89      0.86       111\n",
      "          22       0.81      0.48      0.60        54\n",
      "          23       0.56      0.93      0.70        40\n",
      "          24       0.96      0.59      0.73        39\n",
      "\n",
      "    accuracy                           0.79      1111\n",
      "   macro avg       0.77      0.78      0.75      1111\n",
      "weighted avg       0.81      0.79      0.79      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now test the validation set on the fitted model\n",
    "rfYPrediction = clf.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, rfYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8778c42c",
   "metadata": {},
   "source": [
    "#### Average of Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97e021af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy for 40% Training Data:  0.9959451550873673\n",
      "Average F-1 Accuracy for 40% Training Data:  0.7833333333333333\n"
     ]
    }
   ],
   "source": [
    "average_accuracy40 = (0.9959869576122398 + 0.9948582894406822 + 0.9969902182091799)/3\n",
    "average_F140 = (0.78 + 0.80 + 0.77)/3\n",
    "print(\"Average Accuracy for 40% Training Data: \", average_accuracy40)\n",
    "print(\"Average F-1 Accuracy for 40% Training Data: \", average_F140)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e458b72",
   "metadata": {},
   "source": [
    "### 60% Training Set Data, Validation Set Same Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a7d02c",
   "metadata": {},
   "source": [
    "#### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fc69fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-49b491fca1f5>:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xtrain_maxabs, ytrain)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9957364989132252\n"
     ]
    }
   ],
   "source": [
    "#Split the training data into testing and training parts. Use 40% of it as test data, remaining is training.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(connectionData, y, test_size = 0.40)\n",
    "\n",
    "#Transform the training set with the appropriate scaler.\n",
    "xtrain_maxabs = max_abs_scaler.fit_transform(xtrain)\n",
    "\n",
    "#Create a classifier\n",
    "clf=RandomForestClassifier(n_estimators=6)\n",
    "\n",
    "#Train the model and set up the y prediction variable\n",
    "clf.fit(xtrain_maxabs, ytrain)\n",
    "\n",
    "rf_score = clf.score(xtrain_maxabs, ytrain)\n",
    "print(\"Score: \", rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d211e463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83        78\n",
      "           1       0.93      0.82      0.87       208\n",
      "           2       0.84      0.86      0.85       165\n",
      "           3       0.87      0.89      0.88        85\n",
      "          10       0.71      0.83      0.77        30\n",
      "          11       0.94      0.57      0.71       143\n",
      "          12       0.53      0.79      0.63        87\n",
      "          13       0.77      0.85      0.81        47\n",
      "          20       0.59      0.83      0.69        24\n",
      "          21       0.88      0.89      0.89       111\n",
      "          22       0.84      0.57      0.68        54\n",
      "          23       0.55      0.93      0.69        40\n",
      "          24       0.95      0.51      0.67        39\n",
      "\n",
      "    accuracy                           0.80      1111\n",
      "   macro avg       0.78      0.79      0.77      1111\n",
      "weighted avg       0.83      0.80      0.80      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now test the validation set on the fitted model\n",
    "rfYPrediction = clf.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, rfYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46386d2",
   "metadata": {},
   "source": [
    "#### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f55d29c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-dd7e6b148503>:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xtrain_maxabs, ytrain)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9968232737000502\n"
     ]
    }
   ],
   "source": [
    "#Split the training data into testing and training parts. Use 40% of it as test data, remaining is training.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(connectionData, y, test_size = 0.40)\n",
    "#Transform the training set with the appropriate scaler.\n",
    "xtrain_maxabs = max_abs_scaler.fit_transform(xtrain)\n",
    "#Train the model and set up the y prediction variable\n",
    "clf.fit(xtrain_maxabs, ytrain)\n",
    "\n",
    "rf_score = clf.score(xtrain_maxabs, ytrain)\n",
    "print(\"Score: \", rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da4fd048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.84        78\n",
      "           1       0.89      0.88      0.89       208\n",
      "           2       0.85      0.82      0.84       165\n",
      "           3       0.86      0.80      0.83        85\n",
      "          10       0.56      0.83      0.67        30\n",
      "          11       0.93      0.54      0.68       143\n",
      "          12       0.59      0.86      0.70        87\n",
      "          13       0.77      0.85      0.81        47\n",
      "          20       0.64      0.88      0.74        24\n",
      "          21       0.84      0.88      0.86       111\n",
      "          22       0.84      0.50      0.63        54\n",
      "          23       0.57      0.95      0.71        40\n",
      "          24       0.95      0.49      0.64        39\n",
      "\n",
      "    accuracy                           0.79      1111\n",
      "   macro avg       0.77      0.78      0.76      1111\n",
      "weighted avg       0.82      0.79      0.79      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now test the validation set on the fitted model\n",
    "rfYPrediction = clf.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, rfYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18468344",
   "metadata": {},
   "source": [
    "#### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a4b3595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-dd7e6b148503>:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xtrain_maxabs, ytrain)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9969904698211002\n"
     ]
    }
   ],
   "source": [
    "#Split the training data into testing and training parts. Use 40% of it as test data, remaining is training.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(connectionData, y, test_size = 0.40)\n",
    "#Transform the training set with the appropriate scaler.\n",
    "xtrain_maxabs = max_abs_scaler.fit_transform(xtrain)\n",
    "#Train the model and set up the y prediction variable\n",
    "clf.fit(xtrain_maxabs, ytrain)\n",
    "\n",
    "rf_score = clf.score(xtrain_maxabs, ytrain)\n",
    "print(\"Score: \", rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e154091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77        78\n",
      "           1       0.93      0.80      0.86       208\n",
      "           2       0.84      0.91      0.87       165\n",
      "           3       0.95      0.81      0.87        85\n",
      "          10       0.62      0.67      0.65        30\n",
      "          11       0.91      0.61      0.73       143\n",
      "          12       0.59      0.84      0.70        87\n",
      "          13       0.67      0.79      0.73        47\n",
      "          20       0.55      0.92      0.69        24\n",
      "          21       0.81      0.87      0.84       111\n",
      "          22       0.84      0.39      0.53        54\n",
      "          23       0.60      0.93      0.73        40\n",
      "          24       0.92      0.56      0.70        39\n",
      "\n",
      "    accuracy                           0.78      1111\n",
      "   macro avg       0.76      0.77      0.74      1111\n",
      "weighted avg       0.81      0.78      0.78      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now test the validation set on the fitted model\n",
    "rfYPrediction = clf.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, rfYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ef4a5d",
   "metadata": {},
   "source": [
    "#### Average of Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40555667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy for 60% Training Data:  0.9967954076798752\n",
      "Average F-1 Accuracy for 60% Training Data:  0.7833333333333333\n"
     ]
    }
   ],
   "source": [
    "average_accuracy60 = (0.9970740678816251 + 0.9963216853369001 + 0.9969904698211002)/3\n",
    "average_F160 = (0.78 + 0.78 + 0.79)/3\n",
    "print(\"Average Accuracy for 60% Training Data: \", average_accuracy60)\n",
    "print(\"Average F-1 Accuracy for 60% Training Data: \", average_F160)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01da1791",
   "metadata": {},
   "source": [
    "### 80% Training Set Data, Validation Set Same Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d7466c",
   "metadata": {},
   "source": [
    "#### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76202705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-d4653d871c63>:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xtrain_maxabs, ytrain)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9970531067778544\n"
     ]
    }
   ],
   "source": [
    "#Split the training data into testing and training parts. Use 20% of it as test data, remaining is training.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(connectionData, y, test_size = 0.20)\n",
    "\n",
    "#Transform the training set with the appropriate scaler.\n",
    "xtrain_maxabs = max_abs_scaler.fit_transform(xtrain)\n",
    "\n",
    "#Create a classifier\n",
    "clf=RandomForestClassifier(n_estimators=6)\n",
    "\n",
    "#Train the model and set up the y prediction variable\n",
    "clf.fit(xtrain_maxabs, ytrain)\n",
    "\n",
    "rf_score = clf.score(xtrain_maxabs, ytrain)\n",
    "print(\"Score: \", rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "efa96a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.91      0.80        78\n",
      "           1       0.94      0.84      0.89       208\n",
      "           2       0.88      0.92      0.90       165\n",
      "           3       0.93      0.87      0.90        85\n",
      "          10       0.67      0.80      0.73        30\n",
      "          11       0.95      0.63      0.76       143\n",
      "          12       0.60      0.87      0.71        87\n",
      "          13       0.83      0.83      0.83        47\n",
      "          20       0.53      0.83      0.65        24\n",
      "          21       0.83      0.83      0.83       111\n",
      "          22       0.76      0.46      0.57        54\n",
      "          23       0.60      0.95      0.74        40\n",
      "          24       0.96      0.59      0.73        39\n",
      "\n",
      "    accuracy                           0.81      1111\n",
      "   macro avg       0.78      0.79      0.77      1111\n",
      "weighted avg       0.84      0.81      0.81      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now test the validation set on the fitted model\n",
    "rfYPrediction = clf.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, rfYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07145d5d",
   "metadata": {},
   "source": [
    "#### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d259ca6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-fd6063f22498>:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xtrain_maxabs, ytrain)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9967396074989028\n"
     ]
    }
   ],
   "source": [
    "#Split the training data into testing and training parts. Use 20% of it as test data, remaining is training.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(connectionData, y, test_size = 0.20)\n",
    "#Transform the training set with the appropriate scaler.\n",
    "xtrain_maxabs = max_abs_scaler.fit_transform(xtrain)\n",
    "#Train the model and set up the y prediction variable\n",
    "clf.fit(xtrain_maxabs, ytrain)\n",
    "\n",
    "rf_score = clf.score(xtrain_maxabs, ytrain)\n",
    "print(\"Score: \", rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "16d754f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.94      0.76        78\n",
      "           1       0.92      0.79      0.85       208\n",
      "           2       0.85      0.84      0.84       165\n",
      "           3       0.90      0.81      0.85        85\n",
      "          10       0.70      0.77      0.73        30\n",
      "          11       0.97      0.60      0.74       143\n",
      "          12       0.60      0.90      0.72        87\n",
      "          13       0.75      0.83      0.79        47\n",
      "          20       0.58      0.92      0.71        24\n",
      "          21       0.80      0.81      0.80       111\n",
      "          22       0.68      0.43      0.52        54\n",
      "          23       0.52      0.85      0.64        40\n",
      "          24       0.90      0.49      0.63        39\n",
      "\n",
      "    accuracy                           0.77      1111\n",
      "   macro avg       0.75      0.77      0.74      1111\n",
      "weighted avg       0.81      0.77      0.77      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now test the validation set on the fitted model\n",
    "rfYPrediction = clf.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, rfYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de81d4a",
   "metadata": {},
   "source": [
    "#### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39e3c262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-fd6063f22498>:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xtrain_maxabs, ytrain)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9966769076431125\n"
     ]
    }
   ],
   "source": [
    "#Split the training data into testing and training parts. Use 20% of it as test data, remaining is training.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(connectionData, y, test_size = 0.20)\n",
    "#Transform the training set with the appropriate scaler.\n",
    "xtrain_maxabs = max_abs_scaler.fit_transform(xtrain)\n",
    "#Train the model and set up the y prediction variable\n",
    "clf.fit(xtrain_maxabs, ytrain)\n",
    "\n",
    "rf_score = clf.score(xtrain_maxabs, ytrain)\n",
    "print(\"Score: \", rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85d4bd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.91      0.74        78\n",
      "           1       0.91      0.78      0.84       208\n",
      "           2       0.84      0.81      0.82       165\n",
      "           3       0.83      0.81      0.82        85\n",
      "          10       0.60      0.83      0.69        30\n",
      "          11       0.95      0.58      0.72       143\n",
      "          12       0.66      0.91      0.76        87\n",
      "          13       0.72      0.89      0.80        47\n",
      "          20       0.65      0.83      0.73        24\n",
      "          21       0.82      0.87      0.85       111\n",
      "          22       0.77      0.50      0.61        54\n",
      "          23       0.55      0.95      0.70        40\n",
      "          24       1.00      0.41      0.58        39\n",
      "\n",
      "    accuracy                           0.78      1111\n",
      "   macro avg       0.76      0.78      0.74      1111\n",
      "weighted avg       0.81      0.78      0.78      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now test the validation set on the fitted model\n",
    "rfYPrediction = clf.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, rfYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489ee900",
   "metadata": {},
   "source": [
    "#### Average of Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "add719ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy for 80% Training Data:  0.9966769076431125\n",
      "Average F-1 Accuracy for 80% Training Data:  0.7966666666666667\n"
     ]
    }
   ],
   "source": [
    "average_accuracy80 = (0.9966142077873221 + 0.9968650072104834 + 0.9965515079315318)/3\n",
    "average_F180 = (0.80 + 0.79 + 0.80)/3\n",
    "print(\"Average Accuracy for 80% Training Data: \", average_accuracy80)\n",
    "print(\"Average F-1 Accuracy for 80% Training Data: \", average_F180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd65cf3",
   "metadata": {},
   "source": [
    "### 100% Training Set Data, Validation Set Same Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b4566c",
   "metadata": {},
   "source": [
    "#### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2864fe03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-53-6f2d2d36636e>:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xtrain_maxabs, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9967397301499724\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform the predictor columns for training and validation datasets\n",
    "xtrain_maxabs = max_abs_scaler.fit_transform(connectionData)\n",
    "xval_maxabs = max_abs_scaler.fit_transform(valConnectionData)\n",
    "\n",
    "#Select out response columns from data frames\n",
    "y = df.loc[:,['Building_Code']]\n",
    "val_y = val_df['Building_Code']\n",
    "\n",
    "#Create a classifier\n",
    "clf=RandomForestClassifier(n_estimators=6)\n",
    "\n",
    "#Train the model and set up the y prediction variable\n",
    "clf.fit(xtrain_maxabs, y)\n",
    "\n",
    "rf_score = clf.score(xtrain_maxabs, y)\n",
    "print(\"Score: \", rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b2e991b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.80        78\n",
      "           1       0.92      0.84      0.88       208\n",
      "           2       0.85      0.89      0.87       165\n",
      "           3       0.95      0.84      0.89        85\n",
      "          10       0.79      0.77      0.78        30\n",
      "          11       0.94      0.62      0.75       143\n",
      "          12       0.59      0.85      0.69        87\n",
      "          13       0.72      0.81      0.76        47\n",
      "          20       0.73      0.92      0.81        24\n",
      "          21       0.88      0.90      0.89       111\n",
      "          22       0.84      0.50      0.63        54\n",
      "          23       0.49      0.95      0.65        40\n",
      "          24       0.95      0.46      0.62        39\n",
      "\n",
      "    accuracy                           0.80      1111\n",
      "   macro avg       0.80      0.79      0.77      1111\n",
      "weighted avg       0.84      0.80      0.80      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now test the validation set on the fitted model\n",
    "rfYPrediction = clf.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, rfYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573761a8",
   "metadata": {},
   "source": [
    "#### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e712b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-6f2d2d36636e>:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xtrain_maxabs, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9967397301499724\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform the predictor columns for training and validation datasets\n",
    "xtrain_maxabs = max_abs_scaler.fit_transform(connectionData)\n",
    "xval_maxabs = max_abs_scaler.fit_transform(valConnectionData)\n",
    "\n",
    "#Select out response columns from data frames\n",
    "y = df.loc[:,['Building_Code']]\n",
    "val_y = val_df['Building_Code']\n",
    "\n",
    "#Create a classifier\n",
    "clf=RandomForestClassifier(n_estimators=6)\n",
    "\n",
    "#Train the model and set up the y prediction variable\n",
    "clf.fit(xtrain_maxabs, y)\n",
    "\n",
    "rf_score = clf.score(xtrain_maxabs, y)\n",
    "print(\"Score: \", rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b29b8195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.81        78\n",
      "           1       0.88      0.82      0.85       208\n",
      "           2       0.90      0.85      0.88       165\n",
      "           3       0.96      0.86      0.91        85\n",
      "          10       0.50      0.70      0.58        30\n",
      "          11       0.89      0.57      0.70       143\n",
      "          12       0.63      0.83      0.71        87\n",
      "          13       0.72      0.87      0.79        47\n",
      "          20       0.68      0.88      0.76        24\n",
      "          21       0.84      0.86      0.85       111\n",
      "          22       0.79      0.57      0.67        54\n",
      "          23       0.51      0.90      0.65        40\n",
      "          24       1.00      0.36      0.53        39\n",
      "\n",
      "    accuracy                           0.79      1111\n",
      "   macro avg       0.77      0.77      0.74      1111\n",
      "weighted avg       0.82      0.79      0.79      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now test the validation set on the fitted model\n",
    "rfYPrediction = clf.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, rfYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01e4eec",
   "metadata": {},
   "source": [
    "#### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7588fada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-6f2d2d36636e>:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xtrain_maxabs, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9969403621407433\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform the predictor columns for training and validation datasets\n",
    "xtrain_maxabs = max_abs_scaler.fit_transform(connectionData)\n",
    "xval_maxabs = max_abs_scaler.fit_transform(valConnectionData)\n",
    "\n",
    "#Select out response columns from data frames\n",
    "y = df.loc[:,['Building_Code']]\n",
    "val_y = val_df['Building_Code']\n",
    "\n",
    "#Create a classifier\n",
    "clf=RandomForestClassifier(n_estimators=6)\n",
    "\n",
    "#Train the model and set up the y prediction variable\n",
    "clf.fit(xtrain_maxabs, y)\n",
    "\n",
    "rf_score = clf.score(xtrain_maxabs, y)\n",
    "print(\"Score: \", rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fdf5c84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.91      0.76        78\n",
      "           1       0.91      0.79      0.85       208\n",
      "           2       0.88      0.88      0.88       165\n",
      "           3       0.89      0.84      0.86        85\n",
      "          10       0.59      0.77      0.67        30\n",
      "          11       0.94      0.59      0.72       143\n",
      "          12       0.61      0.85      0.71        87\n",
      "          13       0.65      0.79      0.71        47\n",
      "          20       0.69      0.92      0.79        24\n",
      "          21       0.88      0.88      0.88       111\n",
      "          22       0.85      0.61      0.71        54\n",
      "          23       0.58      0.90      0.71        40\n",
      "          24       0.96      0.64      0.77        39\n",
      "\n",
      "    accuracy                           0.80      1111\n",
      "   macro avg       0.78      0.80      0.77      1111\n",
      "weighted avg       0.83      0.80      0.80      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now test the validation set on the fitted model\n",
    "rfYPrediction = clf.predict(xval_maxabs)\n",
    "\n",
    "cr = classification_report(val_y, rfYPrediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5676983",
   "metadata": {},
   "source": [
    "#### Average of Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2c10270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy for 100% Training Data:  0.9968233268127936\n",
      "Average F-1 Accuracy for 100% Training Data:  0.7933333333333333\n"
     ]
    }
   ],
   "source": [
    "average_accuracy100 = (0.996990520138436 + 0.9968902041430506 + 0.9965892561568942)/3\n",
    "average_F1100 = (0.80 + 0.78 + 0.80)/3\n",
    "print(\"Average Accuracy for 100% Training Data: \", average_accuracy100)\n",
    "print(\"Average F-1 Accuracy for 100% Training Data: \", average_F1100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6789b21f",
   "metadata": {},
   "source": [
    "### Plots of Average Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ee90dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Set what to plot for the x/y axis\n",
    "xAxis = [0.9951509071147897, 0.9959451550873673, 0.9967954076798752, 0.9966769076431125, 0.9968233268127936]\n",
    "yAxis = [20, 40, 60, 80, 100]\n",
    "\n",
    "#Set graph title, x-axis title, y-axis title, and plot the line graph\n",
    "plt.plot(xAxis,yAxis, color = 'green', marker = 'o')\n",
    "plt.title('Average Prediction Accuracy for Amount of Training Data')\n",
    "plt.xlabel('Prediction Accuracy')\n",
    "plt.ylabel('Amount of Training Data Used')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3466d30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Set what to plot for the x/y axis\n",
    "xAxis = [0.7433333333333333, 0.7833333333333333, 0.7833333333333333, 0.7966666666666667, 0.7933333333333333]\n",
    "yAxis = [20, 40, 60, 80, 100]\n",
    "\n",
    "#Set graph title, x-axis title, y-axis title, and plot the line graph\n",
    "plt.plot(xAxis,yAxis, color = 'blue', marker = 'o')\n",
    "plt.title('Average F-1 Accuracy for Amount of Training Data')\n",
    "plt.xlabel('F-1 Accuracy')\n",
    "plt.ylabel('Amount of Training Data Used')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
